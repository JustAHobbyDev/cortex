#!/usr/bin/env python3
"""
Cortex Project Coach v0

CLI to bootstrap and audit `.cortex/` lifecycle artifacts in a target project.
"""

from __future__ import annotations

import argparse
import json
import re
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import jsonschema


MANIFEST_FILE = "manifest_v0.json"
LIFECYCLE_SCHEMA_VERSION = "v0"
PHASE_ORDER = [
    "direction_defined",
    "governance_defined",
    "design_spec_compiled",
    "lifecycle_audited",
]
VALID_APPLY_SCOPES = {"direction", "governance", "design"}


def utc_now() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def write_if_missing(path: Path, content: str, force: bool) -> bool:
    path.parent.mkdir(parents=True, exist_ok=True)
    if path.exists() and not force:
        return False
    path.write_text(content, encoding="utf-8")
    return True


def repo_root_from_script() -> Path:
    return Path(__file__).resolve().parents[1]


def default_design_dsl(project_id: str, project_name: str) -> str:
    return f"""# Generated by cortex_project_coach_v0.py
id {project_id}_design_v0
version v0
name {project_name} Design Baseline

token layout.grid | 12-column asymmetric grid
token layout.spacing | 96px vertical rhythm
token layout.structure | hero-dominant above fold
set layout.density | "balanced"
set layout.rhythm | "alternating panel cadence"
set layout.narrative_flow | "problem-to-solution arc"

token typography.hero | oversized neo-grotesk hero
set typography.body | "high x-height body face with line-height breathing room"
set typography.families | ["Space Grotesk", "IBM Plex Sans"]
set typography.scale | "optical size contrast"
set typography.weight_strategy | "weight-contrast ladder"
token typography.tracking_strategy | tight display tracking

token surface.base | charcoal base layer
token surface.accent | electric accent glow
token surface.panels | frosted glass panel
token surface.depth_model | hybrid
token surface.shadows | ambient shadow cloud
add surface.textures | "restrained gradient diffusion"

token motion.scroll | fade-up staggered reveal
token motion.hover | 200ms ease-out hover scale
token motion.timing_profile | snappy timing profile
add motion.interaction_signatures | "magnetic CTA pull"
set motion.reduced_motion_strategy | "opacity-only fallback"

token influence.primary | Swiss grid discipline
token influence.secondary | SaaS futurism
token influence.style_cluster | tech minimalism cluster
add influence.anti_patterns | "avoid ornamental motion"

score clarity | 8
score novelty | 7
score usability | 8
score brand_fit | 8
"""


def init_project(args: argparse.Namespace) -> int:
    project_dir = Path(args.project_dir).resolve()
    cortex_dir = project_dir / ".cortex"
    artifacts_dir = cortex_dir / "artifacts"
    prompts_dir = cortex_dir / "prompts"
    reports_dir = cortex_dir / "reports"
    project_id = args.project_id
    project_name = args.project_name

    manifest = {
        "version": LIFECYCLE_SCHEMA_VERSION,
        "project_id": project_id,
        "project_name": project_name,
        "created_at": utc_now(),
        "updated_at": utc_now(),
        "phases": {
            "direction_defined": False,
            "governance_defined": False,
            "design_spec_compiled": False,
            "lifecycle_audited": False,
        },
        "artifacts": {
            "direction": f".cortex/artifacts/direction_{project_id}_v0.md",
            "governance": f".cortex/artifacts/governance_{project_id}_v0.md",
            "design_dsl": f".cortex/artifacts/design_{project_id}_v0.dsl",
            "design_json": f".cortex/artifacts/design_{project_id}_v0.json",
            "project_prompt": f".cortex/prompts/project_coach_prompt_{project_id}_v0.md",
        },
    }

    direction_md = f"""# {project_name} Direction v0

## North Star
- Define the single most important project outcome.

## Anti-Goals
- List what this project will explicitly avoid.

## Success Signals
- Define measurable outcomes for a successful first release.
"""
    governance_md = f"""# {project_name} Governance v0

## Invariants
- No silent mutation of core artifacts.
- Version bumps for semantic changes.
- Fail closed when required fields are missing.

## Delivery Constraints
- Accessibility and usability checks required before release.
- Deterministic artifact generation where applicable.
"""
    prompt_md = f"""# Project Coach Prompt ({project_id}) v0

Use `.cortex/manifest_v0.json` and `.cortex/artifacts/*` as source of truth.

Tasks:
1. Propose concrete updates to direction/governance/design artifacts.
2. Keep changes versioned (`vN`) and explicit.
3. Report lifecycle gaps and next corrective action.
"""

    changed = []
    changed.append(write_if_missing(cortex_dir / MANIFEST_FILE, json.dumps(manifest, indent=2, sort_keys=True) + "\n", args.force))
    changed.append(write_if_missing(artifacts_dir / f"direction_{project_id}_v0.md", direction_md, args.force))
    changed.append(write_if_missing(artifacts_dir / f"governance_{project_id}_v0.md", governance_md, args.force))
    changed.append(write_if_missing(artifacts_dir / f"design_{project_id}_v0.dsl", default_design_dsl(project_id, project_name), args.force))
    changed.append(write_if_missing(prompts_dir / f"project_coach_prompt_{project_id}_v0.md", prompt_md, args.force))
    reports_dir.mkdir(parents=True, exist_ok=True)

    # Compile DSL to JSON via existing compiler.
    repo_root = repo_root_from_script()
    dsl_path = artifacts_dir / f"design_{project_id}_v0.dsl"
    json_path = artifacts_dir / f"design_{project_id}_v0.json"
    compile_cmd = [
        sys.executable,
        str(repo_root / "scripts" / "design_prompt_dsl_compile_v0.py"),
        "--dsl-file",
        str(dsl_path),
        "--out-file",
        str(json_path),
        "--vocab-file",
        str(repo_root / "templates" / "modern_web_design_vocabulary_v0.json"),
    ]
    proc = subprocess.run(compile_cmd, capture_output=True, text=True, check=False)
    if proc.returncode != 0:
        print(proc.stderr.strip() or proc.stdout.strip(), file=sys.stderr)
        return 1

    # Update manifest progress flags.
    manifest_path = cortex_dir / MANIFEST_FILE
    manifest_obj = json.loads(manifest_path.read_text(encoding="utf-8"))
    manifest_obj["updated_at"] = utc_now()
    manifest_obj["phases"]["direction_defined"] = True
    manifest_obj["phases"]["governance_defined"] = True
    manifest_obj["phases"]["design_spec_compiled"] = True
    manifest_path.write_text(json.dumps(manifest_obj, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    print(f"initialized: {project_dir}")
    if args.force:
        print("mode: force (existing files may be overwritten)")
    else:
        created_count = sum(1 for c in changed if c)
        print(f"created_or_updated_files: {created_count}")
    return 0


def validate_design_json(design_json: Path, schema: Path) -> tuple[bool, str]:
    try:
        schema_obj = json.loads(schema.read_text(encoding="utf-8"))
        data_obj = json.loads(design_json.read_text(encoding="utf-8"))
        jsonschema.validate(instance=data_obj, schema=schema_obj)
        return True, ""
    except Exception as exc:  # noqa: BLE001
        return False, str(exc)


def compute_audit_report(project_dir: Path) -> tuple[str, dict[str, Any]]:
    cortex_dir = project_dir / ".cortex"
    manifest_path = cortex_dir / MANIFEST_FILE
    repo_root = repo_root_from_script()
    schema_path = repo_root / "templates" / "design_ontology_v0.schema.json"

    checks: list[dict[str, Any]] = []
    status = "pass"

    required = [
        manifest_path,
        cortex_dir / "artifacts",
        cortex_dir / "prompts",
        cortex_dir / "reports",
    ]
    for p in required:
        exists = p.exists()
        checks.append({"check": f"exists:{p.relative_to(project_dir)}", "status": "pass" if exists else "fail"})
        if not exists:
            status = "fail"

    manifest_obj: dict[str, Any] | None = None
    if manifest_path.exists():
        try:
            manifest_obj = json.loads(manifest_path.read_text(encoding="utf-8"))
            if manifest_obj.get("version") != LIFECYCLE_SCHEMA_VERSION:
                checks.append({"check": "manifest_version", "status": "fail", "detail": f"expected {LIFECYCLE_SCHEMA_VERSION}"})
                status = "fail"
            else:
                checks.append({"check": "manifest_version", "status": "pass"})
        except Exception as exc:  # noqa: BLE001
            checks.append({"check": "manifest_parse", "status": "fail", "detail": str(exc)})
            status = "fail"

    design_json_path: Path | None = None
    if manifest_obj:
        path = manifest_obj.get("artifacts", {}).get("design_json")
        if isinstance(path, str):
            design_json_path = project_dir / path

    if design_json_path is not None and design_json_path.exists():
        ok, detail = validate_design_json(design_json_path, schema_path)
        checks.append(
            {
                "check": "design_schema_validation",
                "status": "pass" if ok else "fail",
                "detail": detail,
            }
        )
        if not ok:
            status = "fail"
    else:
        checks.append({"check": "design_schema_validation", "status": "fail", "detail": "design_json missing"})
        status = "fail"

    report = {
        "version": "v0",
        "run_at": utc_now(),
        "project_dir": str(project_dir),
        "status": status,
        "checks": checks,
    }
    return status, report


def infer_phase_status(project_dir: Path, manifest_obj: dict[str, Any]) -> dict[str, bool]:
    artifacts = manifest_obj.get("artifacts", {})
    direction_path = artifacts.get("direction")
    governance_path = artifacts.get("governance")
    design_dsl_path = artifacts.get("design_dsl")
    design_json_path = artifacts.get("design_json")

    inferred = {
        "direction_defined": isinstance(direction_path, str) and (project_dir / direction_path).exists(),
        "governance_defined": isinstance(governance_path, str) and (project_dir / governance_path).exists(),
        "design_spec_compiled": isinstance(design_dsl_path, str)
        and isinstance(design_json_path, str)
        and (project_dir / design_dsl_path).exists()
        and (project_dir / design_json_path).exists(),
        "lifecycle_audited": False,
    }
    return inferred


def next_versioned_path(path: Path) -> Path:
    m = re.search(r"_v(\d+)(\.[A-Za-z0-9]+)$", path.name)
    if not m:
        return path.with_name(f"{path.stem}_draft{path.suffix}")
    current = int(m.group(1))
    ext = m.group(2)
    next_name = re.sub(r"_v\d+" + re.escape(ext) + r"$", f"_v{current + 1}{ext}", path.name)
    return path.with_name(next_name)


def parse_apply_scopes(raw: str) -> set[str]:
    scopes = {s.strip().lower() for s in raw.split(",") if s.strip()}
    if not scopes:
        return set(VALID_APPLY_SCOPES)
    unknown = scopes - VALID_APPLY_SCOPES
    if unknown:
        raise ValueError(
            "invalid apply scope(s): "
            + ", ".join(sorted(unknown))
            + f"; valid: {', '.join(sorted(VALID_APPLY_SCOPES))}"
        )
    return scopes


def classify_artifact_scope(target: str) -> str | None:
    name = Path(target).name
    if name.startswith("direction_"):
        return "direction"
    if name.startswith("governance_"):
        return "governance"
    if name.startswith("design_"):
        return "design"
    return None


def apply_coach_actions(
    project_dir: Path,
    actions: list[dict[str, str]],
    cycle_id: str,
    apply_scopes: set[str],
) -> tuple[list[dict[str, str]], list[dict[str, str]]]:
    applied: list[dict[str, str]] = []
    skipped: list[dict[str, str]] = []
    for action in actions:
        target = action.get("target", "")
        step = action.get("step", "")
        instruction = action.get("instruction", "")
        if not isinstance(target, str) or not target.startswith(".cortex/artifacts/"):
            skipped.append({"target": str(target), "reason": "non-artifact target"})
            continue
        scope = classify_artifact_scope(target)
        if scope is None:
            skipped.append({"target": str(target), "reason": "unclassified artifact scope"})
            continue
        if scope not in apply_scopes:
            skipped.append({"target": str(target), "reason": f"scope excluded: {scope}"})
            continue

        src = project_dir / target
        dst = next_versioned_path(src)
        dst.parent.mkdir(parents=True, exist_ok=True)

        if src.exists():
            content = src.read_text(encoding="utf-8")
        else:
            content = ""

        if dst.suffix == ".md":
            draft = (
                f"# Draft from {src.name if src.name else target}\n\n"
                f"- cycle_id: `{cycle_id}`\n"
                f"- action: `{step}`\n"
                f"- instruction: {instruction}\n\n"
                "## Proposed Update\n"
                + (content if content else "- Fill this artifact according to action instruction.\n")
            )
            dst.write_text(draft, encoding="utf-8")
        elif dst.suffix == ".dsl":
            lines = content.splitlines()
            out_lines: list[str] = [f"# Draft generated by coach cycle {cycle_id}"]
            replaced_version = False
            for line in lines:
                if line.startswith("version "):
                    m = re.search(r"_v(\d+)$", dst.stem)
                    next_ver = f"v{m.group(1)}" if m else "v1"
                    out_lines.append(f"version {next_ver}")
                    replaced_version = True
                elif line.startswith("id ") and re.search(r"_v\d+$", line):
                    out_lines.append(re.sub(r"_v\d+$", lambda mm: f"_v{(int(mm.group(0)[2:]) + 1)}", line))
                else:
                    out_lines.append(line)
            if not lines:
                out_lines.extend(
                    [
                        "id draft_design_v1",
                        "version v1",
                        "name Draft Design Spec",
                    ]
                )
            if lines and not replaced_version:
                m = re.search(r"_v(\d+)$", dst.stem)
                next_ver = f"v{m.group(1)}" if m else "v1"
                out_lines.insert(1, f"version {next_ver}")
            dst.write_text("\n".join(out_lines).rstrip() + "\n", encoding="utf-8")
        elif dst.suffix == ".json":
            if content.strip():
                try:
                    obj = json.loads(content)
                except Exception:
                    obj = {"source": src.name, "note": "source was invalid json"}
            else:
                obj = {}
            m = re.search(r"_v(\d+)$", dst.stem)
            next_ver = f"v{m.group(1)}" if m else "v1"
            obj["version"] = next_ver
            obj["generated_by"] = "cortex_project_coach_v0.py"
            obj["generated_cycle_id"] = cycle_id
            obj["action"] = step
            obj["instruction"] = instruction
            dst.write_text(json.dumps(obj, indent=2, sort_keys=True) + "\n", encoding="utf-8")
        else:
            skipped.append({"target": str(target), "reason": f"unsupported extension: {dst.suffix}"})
            continue

        applied.append({"source": str(target), "draft": str(dst.relative_to(project_dir))})
    return applied, skipped


def audit_project(args: argparse.Namespace) -> int:
    project_dir = Path(args.project_dir).resolve()
    cortex_dir = project_dir / ".cortex"
    manifest_path = cortex_dir / MANIFEST_FILE
    status, report = compute_audit_report(project_dir)

    reports_dir = cortex_dir / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)
    out_path = reports_dir / "lifecycle_audit_v0.json"
    out_path.write_text(json.dumps(report, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    # Update manifest lifecycle flag if available.
    if manifest_path.exists():
        try:
            m = json.loads(manifest_path.read_text(encoding="utf-8"))
            m["updated_at"] = utc_now()
            if "phases" in m and isinstance(m["phases"], dict):
                m["phases"]["lifecycle_audited"] = status == "pass"
            manifest_path.write_text(json.dumps(m, indent=2, sort_keys=True) + "\n", encoding="utf-8")
        except Exception:
            pass

    print(str(out_path))
    return 0 if status == "pass" else 1


def coach_project(args: argparse.Namespace) -> int:
    project_dir = Path(args.project_dir).resolve()
    cortex_dir = project_dir / ".cortex"
    manifest_path = cortex_dir / MANIFEST_FILE
    if not manifest_path.exists():
        print(f"missing manifest: {manifest_path}", file=sys.stderr)
        return 1

    try:
        manifest_obj = json.loads(manifest_path.read_text(encoding="utf-8"))
    except Exception as exc:  # noqa: BLE001
        print(f"invalid manifest: {exc}", file=sys.stderr)
        return 1

    inferred = infer_phase_status(project_dir, manifest_obj)
    if args.sync_phases:
        manifest_obj.setdefault("phases", {})
        for phase in PHASE_ORDER:
            if phase in inferred:
                manifest_obj["phases"][phase] = inferred[phase]
        manifest_obj["updated_at"] = utc_now()
        manifest_path.write_text(json.dumps(manifest_obj, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    audit_status, audit_report = compute_audit_report(project_dir)
    reports_dir = cortex_dir / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)
    audit_out = reports_dir / "lifecycle_audit_v0.json"
    audit_out.write_text(json.dumps(audit_report, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    phases = dict(manifest_obj.get("phases", {}))
    phases["lifecycle_audited"] = audit_status == "pass"
    incomplete_phases = [p for p in PHASE_ORDER if not phases.get(p, False)]
    failed_checks = [c for c in audit_report.get("checks", []) if c.get("status") == "fail"]

    cycle_id = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    try:
        apply_scopes = parse_apply_scopes(args.apply_scope)
    except ValueError as exc:
        print(str(exc), file=sys.stderr)
        return 1
    actions: list[dict[str, str]] = []
    if "direction_defined" in incomplete_phases:
        actions.append(
            {
                "step": "Complete direction artifact",
                "target": manifest_obj.get("artifacts", {}).get("direction", ".cortex/artifacts/direction_<id>_v0.md"),
                "instruction": "Fill North Star, Anti-Goals, and Success Signals with concrete measurable statements.",
            }
        )
    if "governance_defined" in incomplete_phases:
        actions.append(
            {
                "step": "Complete governance artifact",
                "target": manifest_obj.get("artifacts", {}).get("governance", ".cortex/artifacts/governance_<id>_v0.md"),
                "instruction": "Define invariants, mutation/versioning rules, and release gates.",
            }
        )
    if "design_spec_compiled" in incomplete_phases:
        actions.append(
            {
                "step": "Compile design DSL into ontology JSON",
                "target": manifest_obj.get("artifacts", {}).get("design_json", ".cortex/artifacts/design_<id>_v0.json"),
                "instruction": "Update DSL and compile using scripts/design_prompt_dsl_compile_v0.py, then revalidate.",
            }
        )

    for check in failed_checks:
        actions.append(
            {
                "step": f"Resolve audit failure: {check.get('check', 'unknown')}",
                "target": ".cortex/reports/lifecycle_audit_v0.json",
                "instruction": check.get("detail", "Inspect and fix related artifact."),
            }
        )

    if not actions:
        actions.append(
            {
                "step": "Advance project lifecycle",
                "target": ".cortex/manifest_v0.json",
                "instruction": "Create next versioned artifacts (`v1`) for changed semantics and rerun coach/audit.",
            }
        )

    applied_drafts: list[dict[str, str]] = []
    skipped_drafts: list[dict[str, str]] = []
    if args.apply:
        applied_drafts, skipped_drafts = apply_coach_actions(project_dir, actions, cycle_id, apply_scopes)

    cycle_report = {
        "version": "v0",
        "cycle_id": cycle_id,
        "run_at": utc_now(),
        "project_id": manifest_obj.get("project_id"),
        "project_name": manifest_obj.get("project_name"),
        "audit_status": audit_status,
        "incomplete_phases": incomplete_phases,
        "failed_checks": failed_checks,
        "actions": actions,
        "apply_mode": args.apply,
        "apply_scope": sorted(apply_scopes),
        "applied_drafts": applied_drafts,
        "skipped_drafts": skipped_drafts,
    }

    cycle_json = reports_dir / f"coach_cycle_{cycle_id}_v0.json"
    cycle_md = reports_dir / f"coach_cycle_{cycle_id}_v0.md"
    prompts_dir = cortex_dir / "prompts"
    prompts_dir.mkdir(parents=True, exist_ok=True)
    cycle_prompt = prompts_dir / f"coach_cycle_prompt_{cycle_id}_v0.md"

    cycle_json.write_text(json.dumps(cycle_report, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    md_lines = [
        "# Coach Cycle Report v0",
        "",
        f"- cycle_id: `{cycle_id}`",
        f"- project_id: `{manifest_obj.get('project_id', '')}`",
        f"- project_name: `{manifest_obj.get('project_name', '')}`",
        f"- audit_status: `{audit_status}`",
        f"- incomplete_phases: `{len(incomplete_phases)}`",
        f"- failed_checks: `{len(failed_checks)}`",
        "",
        "## Actions",
    ]
    for idx, action in enumerate(actions, start=1):
        md_lines.append(f"{idx}. {action['step']} (`{action['target']}`)")
        md_lines.append(f"   {action['instruction']}")
    if args.apply:
        md_lines.extend(["", "## Applied Drafts"])
        if applied_drafts:
            for item in applied_drafts:
                md_lines.append(f"- `{item['source']}` -> `{item['draft']}`")
        else:
            md_lines.append("- none")
        if skipped_drafts:
            md_lines.extend(["", "## Skipped Drafts"])
            for item in skipped_drafts:
                md_lines.append(f"- `{item['target']}` ({item['reason']})")
    cycle_md.write_text("\n".join(md_lines) + "\n", encoding="utf-8")

    prompt_lines = [
        f"# Coach Cycle Prompt ({cycle_id}) v0",
        "",
        "You are assisting the project owner in closing lifecycle gaps.",
        "Use these files as source of truth:",
        "- `.cortex/manifest_v0.json`",
        "- `.cortex/reports/lifecycle_audit_v0.json`",
        f"- `.cortex/reports/{cycle_json.name}`",
        "",
        "Tasks:",
        "1. Propose exact edits to the targeted artifacts for each action.",
        "2. Keep semantics explicit and versioned.",
        "3. After edits, propose rerun commands for audit and next coach cycle.",
    ]
    if args.apply:
        prompt_lines.extend(
            [
                "4. Review generated draft artifacts and propose exact refinements.",
            ]
        )
    cycle_prompt.write_text("\n".join(prompt_lines) + "\n", encoding="utf-8")

    if args.sync_phases:
        manifest_obj.setdefault("phases", {})
        manifest_obj["phases"]["lifecycle_audited"] = audit_status == "pass"
        manifest_obj["updated_at"] = utc_now()
        manifest_path.write_text(json.dumps(manifest_obj, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    print(str(cycle_json))
    print(str(cycle_md))
    print(str(cycle_prompt))
    return 0 if audit_status == "pass" else 1


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Cortex Project Coach v0")
    sub = parser.add_subparsers(dest="cmd", required=True)

    p_init = sub.add_parser("init", help="Bootstrap .cortex artifacts for a project.")
    p_init.add_argument("--project-dir", required=True)
    p_init.add_argument("--project-id", required=True)
    p_init.add_argument("--project-name", required=True)
    p_init.add_argument("--force", action="store_true")
    p_init.set_defaults(func=init_project)

    p_audit = sub.add_parser("audit", help="Audit .cortex lifecycle artifact health.")
    p_audit.add_argument("--project-dir", required=True)
    p_audit.set_defaults(func=audit_project)

    p_coach = sub.add_parser("coach", help="Run one AI-guided lifecycle coaching cycle.")
    p_coach.add_argument("--project-dir", required=True)
    p_coach.add_argument("--no-sync-phases", action="store_false", dest="sync_phases")
    p_coach.add_argument("--apply", action="store_true", help="Generate draft vN+1 artifacts for action targets.")
    p_coach.add_argument(
        "--apply-scope",
        default="direction,governance,design",
        help="Comma-separated scopes for --apply: direction,governance,design",
    )
    p_coach.set_defaults(sync_phases=True)
    p_coach.set_defaults(func=coach_project)

    return parser


def main() -> int:
    parser = build_parser()
    args = parser.parse_args()
    return args.func(args)


if __name__ == "__main__":
    raise SystemExit(main())
